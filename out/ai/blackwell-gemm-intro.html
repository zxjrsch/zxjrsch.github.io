<!DOCTYPE html><!--GWFjHkMuZfgY9jTcVJppH--><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/797e433ab948586e-s.p.dbea232f.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/caa3a2e1cccd8315-s.p.853070df.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/chunks/34db3e12e547f437.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/chunks/4057cc9dbcc744c0.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/be439e04947a2cba.js"/><script src="/_next/static/chunks/922a6be1c048f7e7.js" async=""></script><script src="/_next/static/chunks/748df87cf5306c08.js" async=""></script><script src="/_next/static/chunks/turbopack-0af7db035ef23dbc.js" async=""></script><script src="/_next/static/chunks/988ea292de4c4c73.js" async=""></script><script src="/_next/static/chunks/7a959126392b4956.js" async=""></script><script src="/_next/static/chunks/e02326bdb730da03.js" async=""></script><script src="/_next/static/chunks/bc166ea53d390db7.js" async=""></script><script src="/_next/static/chunks/5ad9eb95768fc0a4.js" async=""></script><meta name="next-size-adjust" content=""/><title>Claire Zhao Blog</title><meta name="description" content="Claire Zhao&#x27;s Blog on AI and Math"/><link rel="icon" href="/favicon.ico?favicon.e10ff5c7.ico" sizes="1176x1032" type="image/x-icon"/><script src="/_next/static/chunks/a6dad97d9634a72d.js" noModule=""></script></head><body class="geist_a71539c9-module__T19VSG__variable geist_mono_8d43a2aa-module__8Li5zG__variable antialiased"><div hidden=""><!--$--><!--/$--></div><div class="flex flex-col justify-center min-h-screen"><div class="flex flex-row justify-center pt-15"><div class="flex flex-row w-full md:max-w-5/10 relative"><div class="flex flex-row md:basis-1/3 "><a href="/"><div class="text-2xl font-bold pl-5 md:pl-0 pt-5 md:pt-0">Claire Zhao</div></a></div><div class="md:hidden grow flex justify-end items-center pr-10"><button><svg width="15" height="15" viewBox="0 0 15 15" fill="none" xmlns="http://www.w3.org/2000/svg" class="size-5"><path d="M8 2H13.5C13.7761 2 14 2.22386 14 2.5V12.5C14 12.7761 13.7761 13 13.5 13H8V2ZM7 2H1.5C1.22386 2 1 2.22386 1 2.5V12.5C1 12.7761 1.22386 13 1.5 13H7V2ZM0 2.5C0 1.67157 0.671573 1 1.5 1H13.5C14.3284 1 15 1.67157 15 2.5V12.5C15 13.3284 14.3284 14 13.5 14H1.5C0.671573 14 0 13.3284 0 12.5V2.5Z" fill="currentColor" fill-rule="evenodd" clip-rule="evenodd"></path></svg></button></div><nav class="hidden md:flex basis-2/3 flex-row justify-end gap-x-8"><a href="/ai"><div class="flex items-center gap-2 font-medium hover:underline">Machine Learning <svg width="15" height="15" viewBox="0 0 15 15" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M9 4L9 11L4.5 7.5L9 4Z" fill="currentColor"></path></svg></div></a><a href="/math"><div class="flex items-center gap-2 font-medium hover:underline">Mathematics </div></a></nav></div></div><div class="grow flex justify-center w-full pt-10 md:pt-15 px-3"><div class="flex flex-col w-full max-w-full md:max-w-2xl lg:max-w-3xl"><div class="text-3xl font-bold flex justify-center">Introduction to Blackwell GEMM</div><div class="text-sm flex justify-center pt-5"></div><div class=""><div><div class=" pt-20 font-bold text-2xl" id="section-2">Specifying the Problem</div><div class="indent-10 md:mt-10 grow text-lg font-medium text-base text-justify"><div class="indent-10 md:mt-5 grow text-lg font-medium text-base text-justify">To compute the matrix product <span class="mt-10"></span> we first need to fix the <span class="font-semibold">IO data type</span> for each of the matrices. We then need to specify the <span class="font-semibold">accumulator data type</span>, this means setting the datatype for summation (math terminology) or reduction (numerics lingo) both of which refer to the operation <span class="mt-10"></span> where <span class="mt-10"></span> are entries, or blocked matrices in <span class="mt-10"></span>. A common accumulator dtype is FP32 to avoid overflow in the summation process. When the accumulator dtype differs from <span class="mt-10"></span>&#x27;s IO type then conversion is required. To produce the block matrix data we use the tensor memory accelerator to load some number of blocks to shared memory, this number is determined by the size of the smem and is sometimes called the number of <span class="font-semibold">TMA pipeline stages</span>. The block matrix product is accumulated on tensor memory, and there are some number of <span class="font-semibold">accumulation stages</span>, which is one in our example.</div><div class="indent-10 md:mt-5 grow text-lg font-medium text-base text-justify">Having specified the data and IO, we turn to compute specifications. We provide the shape for the matrix multiplication instruction for 5th generation TensorCore and specify the block matrix size (aka tiler size in cutlass world) that either one or two CTAs will process at once (the number of CTAs is called the <span class="font-semibold">issue granularity</span> of the instruction). Further we decide the number of threads in each CTA: to ensure full SM usage we use at least the number of threads in a warp group (128).</div></div></div><div><div class=" pt-20 font-bold text-2xl" id="section-2">Host Code</div><div class="indent-10 md:mt-10 grow text-lg font-medium text-base text-justify"><div class="indent-10 md:mt-5 grow text-lg font-medium text-base text-justify">We now describe the host code, which runs on the CPU, and is used to lanuch the GEMM kernel on the GPU.</div><div class="indent-10 md:mt-5 grow text-lg font-medium text-base text-justify">The following specifies the matrix multiply and accumulate instruction to use</div><div class="indent-10 md:mt-5 grow text-lg font-medium text-base text-justify"><div class="relative group my-4 rounded-lg bg-[#1e1e1e] border border-white/10 shadow-lg"><button class="absolute right-3 top-3 z-10 p-2 rounded-md bg-white/10 text-gray-300 opacity-0 group-hover:opacity-100 transition-all duration-200 hover:bg-white/20 hover:text-white" aria-label="Copy code"><svg width="15" height="15" viewBox="0 0 15 15" fill="none" xmlns="http://www.w3.org/2000/svg" class="w-5 h-5"><path d="M1 9.50006C1 10.3285 1.67157 11.0001 2.5 11.0001H4L4 10.0001H2.5C2.22386 10.0001 2 9.7762 2 9.50006L2 2.50006C2 2.22392 2.22386 2.00006 2.5 2.00006L9.5 2.00006C9.77614 2.00006 10 2.22392 10 2.50006V4.00002H5.5C4.67158 4.00002 4 4.67159 4 5.50002V12.5C4 13.3284 4.67158 14 5.5 14H12.5C13.3284 14 14 13.3284 14 12.5V5.50002C14 4.67159 13.3284 4.00002 12.5 4.00002H11V2.50006C11 1.67163 10.3284 1.00006 9.5 1.00006H2.5C1.67157 1.00006 1 1.67163 1 2.50006V9.50006ZM5 5.50002C5 5.22388 5.22386 5.00002 5.5 5.00002H12.5C12.7761 5.00002 13 5.22388 13 5.50002V12.5C13 12.7762 12.7761 13 12.5 13H5.5C5.22386 13 5 12.7762 5 12.5V5.50002Z" fill="currentColor" fill-rule="evenodd" clip-rule="evenodd"></path></svg></button><pre class="overflow-x-auto my-5 py-4 px-4 text-sm font-mono leading-relaxed"><code class=""><div class="table-row"><span style="color:#EEF0F9;font-style:normal;font-weight:normal">op = tcgen05.</span><span style="color:#00DAEF;font-style:normal;font-weight:normal">MmaF16BF16Op</span><span style="color:#EEF0F9;font-style:normal;font-weight:normal">(</span></div><div class="table-row"><span style="color:#EEF0F9;font-style:normal;font-weight:normal">    io_dtype,</span></div><div class="table-row"><span style="color:#EEF0F9;font-style:normal;font-weight:normal">    acc_dtype,</span></div><div class="table-row"><span style="color:#EEF0F9;font-style:normal;font-weight:normal">    mma_inst_shape_mnk,</span></div><div class="table-row"><span style="color:#EEF0F9;font-style:normal;font-weight:normal">    tcgen05.CtaGroup.</span><span style="color:#FFD493;font-style:normal;font-weight:normal">ONE</span><span style="color:#EEF0F9;font-style:normal;font-weight:normal">,   </span><span style="color:#EEF0F98F;font-style:italic;font-weight:normal"># issue granularity</span></div><div class="table-row"><span style="color:#EEF0F9;font-style:normal;font-weight:normal">    tcgen05.OperandSource.</span><span style="color:#FFD493;font-style:normal;font-weight:normal">SMEM</span><span style="color:#EEF0F9;font-style:normal;font-weight:normal">,</span></div><div class="table-row"><span style="color:#EEF0F9;font-style:normal;font-weight:normal">    tcgen05.OperandMajorMode.K, </span><span style="color:#EEF0F98F;font-style:italic;font-weight:normal"># matrix A reduction dimension</span></div><div class="table-row"><span style="color:#EEF0F9;font-style:normal;font-weight:normal">    tcgen05.OperandMajorMode.K, </span><span style="color:#EEF0F98F;font-style:italic;font-weight:normal"># matrix B reduction dimension</span></div><div class="table-row"><span style="color:#EEF0F9;font-style:normal;font-weight:normal">)</span></div><div class="table-row"><span style="color:#EEF0F9;font-style:normal;font-weight:normal">tiled_mma = cute.</span><span style="color:#00DAEF;font-style:normal;font-weight:normal">make_tiled_mma</span><span style="color:#EEF0F9;font-style:normal;font-weight:normal">(op)</span></div><div class="table-row"><span class="inline-block select-none"> </span></div></code></pre></div></div><div class="indent-10 md:mt-5 grow text-lg font-medium text-base text-justify">To specify shared memory layout for the matrix <span class="mt-10"></span>. This layout has at least <span class="mt-10"></span> modes, where the first mode is the shape of the block matrix for a single MMA instruction. The next two modes describe how many times the MMA is repeated traversing the row and columns of <span class="mt-10"></span>. This layout is <span class="font-semibold">swizzled</span> to avoid smem bank conflict.</div><div class="indent-10 md:mt-5 grow text-lg font-medium text-base text-justify"><div class="relative group my-4 rounded-lg bg-[#1e1e1e] border border-white/10 shadow-lg"><button class="absolute right-3 top-3 z-10 p-2 rounded-md bg-white/10 text-gray-300 opacity-0 group-hover:opacity-100 transition-all duration-200 hover:bg-white/20 hover:text-white" aria-label="Copy code"><svg width="15" height="15" viewBox="0 0 15 15" fill="none" xmlns="http://www.w3.org/2000/svg" class="w-5 h-5"><path d="M1 9.50006C1 10.3285 1.67157 11.0001 2.5 11.0001H4L4 10.0001H2.5C2.22386 10.0001 2 9.7762 2 9.50006L2 2.50006C2 2.22392 2.22386 2.00006 2.5 2.00006L9.5 2.00006C9.77614 2.00006 10 2.22392 10 2.50006V4.00002H5.5C4.67158 4.00002 4 4.67159 4 5.50002V12.5C4 13.3284 4.67158 14 5.5 14H12.5C13.3284 14 14 13.3284 14 12.5V5.50002C14 4.67159 13.3284 4.00002 12.5 4.00002H11V2.50006C11 1.67163 10.3284 1.00006 9.5 1.00006H2.5C1.67157 1.00006 1 1.67163 1 2.50006V9.50006ZM5 5.50002C5 5.22388 5.22386 5.00002 5.5 5.00002H12.5C12.7761 5.00002 13 5.22388 13 5.50002V12.5C13 12.7762 12.7761 13 12.5 13H5.5C5.22386 13 5 12.7762 5 12.5V5.50002Z" fill="currentColor" fill-rule="evenodd" clip-rule="evenodd"></path></svg></button><pre class="overflow-x-auto my-5 py-4 px-4 text-sm font-mono leading-relaxed"><code class=""><div class="table-row"><span style="color:#EEF0F9;font-style:normal;font-weight:normal">a_smem_layout = cutlass.utils.blackwell_helpers.</span><span style="color:#00DAEF;font-style:normal;font-weight:normal">make_smem_layout_a</span><span style="color:#EEF0F9;font-style:normal;font-weight:normal">(</span></div><div class="table-row"><span style="color:#EEF0F9;font-style:normal;font-weight:normal">    tiled_mma,</span></div><div class="table-row"><span style="color:#EEF0F9;font-style:normal;font-weight:normal">    mma_tiler_mnk,</span></div><div class="table-row"><span style="color:#EEF0F9;font-style:normal;font-weight:normal">    a.element_type,</span></div><div class="table-row"><span style="color:#EEF0F9;font-style:normal;font-weight:normal">    ab_stages,</span></div><div class="table-row"><span style="color:#EEF0F9;font-style:normal;font-weight:normal">)</span></div><div class="table-row"><span style="color:#EEF0F9;font-style:normal;font-weight:normal">a_smem_layout_one_stage = cute.</span><span style="color:#00DAEF;font-style:normal;font-weight:normal">select</span><span style="color:#EEF0F9;font-style:normal;font-weight:normal">(a_smem_layout, </span><span style="color:#4BF3C8;font-style:italic;font-weight:normal">mode</span><span style="color:#EEF0F9;font-style:normal;font-weight:normal">=[</span><span style="color:#FFD493;font-style:normal;font-weight:normal">0</span><span style="color:#EEF0F9;font-style:normal;font-weight:normal">, </span><span style="color:#FFD493;font-style:normal;font-weight:normal">1</span><span style="color:#EEF0F9;font-style:normal;font-weight:normal">, </span><span style="color:#FFD493;font-style:normal;font-weight:normal">2</span><span style="color:#EEF0F9;font-style:normal;font-weight:normal">])</span></div><div class="table-row"><span class="inline-block select-none"> </span></div></code></pre></div></div><div class="indent-10 md:mt-5 grow text-lg font-medium text-base text-justify">Tensor memory accelerator to load <span class="mt-10"></span> from global to shared memory state space is configured as follows <div class="relative group my-4 rounded-lg bg-[#1e1e1e] border border-white/10 shadow-lg"><button class="absolute right-3 top-3 z-10 p-2 rounded-md bg-white/10 text-gray-300 opacity-0 group-hover:opacity-100 transition-all duration-200 hover:bg-white/20 hover:text-white" aria-label="Copy code"><svg width="15" height="15" viewBox="0 0 15 15" fill="none" xmlns="http://www.w3.org/2000/svg" class="w-5 h-5"><path d="M1 9.50006C1 10.3285 1.67157 11.0001 2.5 11.0001H4L4 10.0001H2.5C2.22386 10.0001 2 9.7762 2 9.50006L2 2.50006C2 2.22392 2.22386 2.00006 2.5 2.00006L9.5 2.00006C9.77614 2.00006 10 2.22392 10 2.50006V4.00002H5.5C4.67158 4.00002 4 4.67159 4 5.50002V12.5C4 13.3284 4.67158 14 5.5 14H12.5C13.3284 14 14 13.3284 14 12.5V5.50002C14 4.67159 13.3284 4.00002 12.5 4.00002H11V2.50006C11 1.67163 10.3284 1.00006 9.5 1.00006H2.5C1.67157 1.00006 1 1.67163 1 2.50006V9.50006ZM5 5.50002C5 5.22388 5.22386 5.00002 5.5 5.00002H12.5C12.7761 5.00002 13 5.22388 13 5.50002V12.5C13 12.7762 12.7761 13 12.5 13H5.5C5.22386 13 5 12.7762 5 12.5V5.50002Z" fill="currentColor" fill-rule="evenodd" clip-rule="evenodd"></path></svg></button><pre class="overflow-x-auto my-5 py-4 px-4 text-sm font-mono leading-relaxed"><code class=""><div class="table-row"><span style="color:#EEF0F9;font-style:normal;font-weight:normal">op = cute.nvgpu.cpasync.</span><span style="color:#00DAEF;font-style:normal;font-weight:normal">CopyBulkTensorTileG2SOp</span><span style="color:#EEF0F9;font-style:normal;font-weight:normal">(tcgen05.CtaGroup.</span><span style="color:#FFD493;font-style:normal;font-weight:normal">ONE</span><span style="color:#EEF0F9;font-style:normal;font-weight:normal">)</span></div><div class="table-row"><span style="color:#EEF0F9;font-style:normal;font-weight:normal">a_tma_atom, a_tma_tensor = cute.nvgpu.</span><span style="color:#00DAEF;font-style:normal;font-weight:normal">make_tiled_tma_atom_A</span><span style="color:#EEF0F9;font-style:normal;font-weight:normal">(</span></div><div class="table-row"><span style="color:#EEF0F9;font-style:normal;font-weight:normal">    op,</span></div><div class="table-row"><span style="color:#EEF0F9;font-style:normal;font-weight:normal">    a,  </span><span style="color:#EEF0F98F;font-style:italic;font-weight:normal"># the matrix A</span></div><div class="table-row"><span style="color:#EEF0F9;font-style:normal;font-weight:normal">    a_smem_layout_one_stage,</span></div><div class="table-row"><span style="color:#EEF0F9;font-style:normal;font-weight:normal">    mma_tiler_mnk,</span></div><div class="table-row"><span style="color:#EEF0F9;font-style:normal;font-weight:normal">    tiled_mma,</span></div><div class="table-row"><span style="color:#EEF0F9;font-style:normal;font-weight:normal">)</span></div><div class="table-row"><span class="inline-block select-none"> </span></div></code></pre></div></div><div class="indent-10 md:mt-5 grow text-lg font-medium text-base text-justify">Then the kernel is lanuched, specifying the thread block and grid dimensions as appropriate.</div></div></div><div><div class=" pt-20 font-bold text-2xl" id="section-2">GEMM Stages</div><div class="indent-10 md:mt-10 grow text-lg font-medium text-base text-justify"><div class="indent-10 md:mt-5 grow text-lg font-medium text-base text-justify">Before delving into device code let us give a conceptual overview of what happens during the GEMM computation.</div><div class="indent-10 md:mt-5 grow text-lg font-medium text-base text-justify">The <span class="font-semibold">prologue</span> is what happens before the matrix multiply instruction occurs. The most important function is to load the data via TMA. This is done by performing the necessary indexing: block, thread, warp ID, which is useful for locating which block matrix the MMA will calculate, which data it should load, the TMA and MMA tensor view. The relevant shared and tensor memory needs to be allocated. Setting up pipelines PipelineTmaUmma for consumer-producer between data loading and MMA, PipelineUmmaAsync for signally accumulation completion.</div><div class="indent-10 md:mt-5 grow text-lg font-medium text-base text-justify">The <span class="font-semibold">mainloop</span> iteratively fetches data, computes MMA and accumulates across the reduction dimension.</div><div class="indent-10 md:mt-5 grow text-lg font-medium text-base text-justify">The <span class="font-semibold">epilogue</span> loads data from tensor memory to register, fuse operation on <span class="mt-10"></span> matrix and performs necessary data conversion. This stages deallocates tensor memory and stores results back to global memory.</div></div></div></div></div></div><div class="flex justify-center my-5 md:my-10">Claire Zhao © 2026</div></div><!--$--><!--/$--><script src="/_next/static/chunks/be439e04947a2cba.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[48523,[\"/_next/static/chunks/988ea292de4c4c73.js\",\"/_next/static/chunks/7a959126392b4956.js\"],\"default\"]\n3:I[82281,[\"/_next/static/chunks/988ea292de4c4c73.js\",\"/_next/static/chunks/7a959126392b4956.js\"],\"default\"]\n4:I[1565,[\"/_next/static/chunks/e02326bdb730da03.js\",\"/_next/static/chunks/bc166ea53d390db7.js\",\"/_next/static/chunks/5ad9eb95768fc0a4.js\"],\"default\"]\n5:I[96045,[\"/_next/static/chunks/e02326bdb730da03.js\",\"/_next/static/chunks/bc166ea53d390db7.js\",\"/_next/static/chunks/5ad9eb95768fc0a4.js\"],\"default\"]\n11:I[75067,[],\"default\"]\n:HL[\"/_next/static/chunks/34db3e12e547f437.css\",\"style\"]\n:HL[\"/_next/static/chunks/4057cc9dbcc744c0.css\",\"style\"]\n:HL[\"/_next/static/media/797e433ab948586e-s.p.dbea232f.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/caa3a2e1cccd8315-s.p.853070df.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"GWFjHkMuZfgY9jTcVJppH\",\"c\":[\"\",\"ai\",\"blackwell-gemm-intro\"],\"q\":\"\",\"i\":false,\"f\":[[[\"\",{\"children\":[\"ai\",{\"children\":[\"blackwell-gemm-intro\",{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/chunks/34db3e12e547f437.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/chunks/4057cc9dbcc744c0.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"geist_a71539c9-module__T19VSG__variable geist_mono_8d43a2aa-module__8Li5zG__variable antialiased\",\"children\":[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"div\",null,{\"className\":\"flex flex-col justify-center min-h-screen\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex flex-row justify-center pt-15\",\"children\":[\"$\",\"$L4\",null,{}]}],[\"$\",\"div\",null,{\"className\":\"grow flex justify-center w-full pt-10 md:pt-15 px-3\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex flex-col w-full max-w-full md:max-w-2xl lg:max-w-3xl\",\"children\":[[\"$\",\"div\",null,{\"className\":\"text-3xl font-bold flex justify-center\",\"children\":\"Introduction to Blackwell GEMM\"}],[\"$\",\"div\",null,{\"className\":\"text-sm flex justify-center pt-5\",\"children\":null}],[\"$\",\"div\",null,{\"className\":\"\",\"children\":[[\"$\",\"div\",\"0\",{\"children\":[[\"$\",\"div\",null,{\"className\":\" pt-20 font-bold text-2xl\",\"id\":\"section-2\",\"children\":\"Specifying the Problem\"}],[\"$\",\"div\",null,{\"className\":\"indent-10 md:mt-10 grow text-lg font-medium text-base text-justify\",\"children\":[[\"$\",\"div\",null,{\"className\":\"indent-10 md:mt-5 grow text-lg font-medium text-base text-justify\",\"children\":[\"To compute the matrix product \",[\"$\",\"$L5\",null,{\"latex\":\"C=AB\",\"className\":\"mt-10\"}],\" we first need to fix the \",[\"$\",\"span\",null,{\"className\":\"font-semibold\",\"children\":\"IO data type\"}],\" for each of the matrices. We then need to specify the \",[\"$\",\"span\",null,{\"className\":\"font-semibold\",\"children\":\"accumulator data type\"}],\", this means setting the datatype for summation (math terminology) or reduction (numerics lingo) both of which refer to the operation \",[\"$\",\"$L5\",null,{\"latex\":\"c_{ij}=\\\\sum_k{a_{ik}b_{kj}}\",\"displayMode\":true,\"className\":\"mt-10\"}],\" where \",[\"$\",\"$L5\",null,{\"latex\":\"a_{ik}, b_{kj}, c_{ij}\",\"className\":\"mt-10\"}],\" are entries, or blocked matrices in \",[\"$\",\"$L5\",null,{\"latex\":\"A, B, C\",\"className\":\"mt-10\"}],\". A common accumulator dtype is FP32 to avoid overflow in the summation process. When the accumulator dtype differs from \",[\"$\",\"$L5\",null,{\"latex\":\"C\",\"className\":\"mt-10\"}],\"'s IO type then conversion is required. To produce the block matrix data we use the tensor memory accelerator to load some number of blocks to shared memory, this number is determined by the size of the smem and is sometimes called the number of \",\"$L6\",\". The block matrix product is accumulated on tensor memory, and there are some number of \",\"$L7\",\", which is one in our example.\"]}],\"$L8\"]}]]}],\"$L9\",\"$La\"]}]]}]}],\"$Lb\"]}],[\"$Lc\",\"$Ld\",\"$Le\"],\"$Lf\"]}],{},null,false,false]},null,false,false]},null,false,false]},null,false,false],\"$L10\",false]],\"m\":\"$undefined\",\"G\":[\"$11\",[]],\"S\":true}\n"])</script><script>self.__next_f.push([1,"15:I[56691,[\"/_next/static/chunks/e02326bdb730da03.js\",\"/_next/static/chunks/bc166ea53d390db7.js\",\"/_next/static/chunks/5ad9eb95768fc0a4.js\"],\"default\"]\n16:I[47259,[\"/_next/static/chunks/988ea292de4c4c73.js\",\"/_next/static/chunks/7a959126392b4956.js\"],\"OutletBoundary\"]\n17:\"$Sreact.suspense\"\n19:I[47259,[\"/_next/static/chunks/988ea292de4c4c73.js\",\"/_next/static/chunks/7a959126392b4956.js\"],\"ViewportBoundary\"]\n1b:I[47259,[\"/_next/static/chunks/988ea292de4c4c73.js\",\"/_next/static/chunks/7a959126392b4956.js\"],\"MetadataBoundary\"]\n6:[\"$\",\"span\",null,{\"className\":\"font-semibold\",\"children\":\"TMA pipeline stages\"}]\n7:[\"$\",\"span\",null,{\"className\":\"font-semibold\",\"children\":\"accumulation stages\"}]\n8:[\"$\",\"div\",null,{\"className\":\"indent-10 md:mt-5 grow text-lg font-medium text-base text-justify\",\"children\":[\"Having specified the data and IO, we turn to compute specifications. We provide the shape for the matrix multiplication instruction for 5th generation TensorCore and specify the block matrix size (aka tiler size in cutlass world) that either one or two CTAs will process at once (the number of CTAs is called the \",[\"$\",\"span\",null,{\"className\":\"font-semibold\",\"children\":\"issue granularity\"}],\" of the instruction). Further we decide the number of threads in each CTA: to ensure full SM usage we use at least the number of threads in a warp group (128).\"]}]\n"])</script><script>self.__next_f.push([1,"9:[\"$\",\"div\",\"1\",{\"children\":[[\"$\",\"div\",null,{\"className\":\" pt-20 font-bold text-2xl\",\"id\":\"section-2\",\"children\":\"Host Code\"}],[\"$\",\"div\",null,{\"className\":\"indent-10 md:mt-10 grow text-lg font-medium text-base text-justify\",\"children\":[[\"$\",\"div\",null,{\"className\":\"indent-10 md:mt-5 grow text-lg font-medium text-base text-justify\",\"children\":\"We now describe the host code, which runs on the CPU, and is used to lanuch the GEMM kernel on the GPU.\"}],[\"$\",\"div\",null,{\"className\":\"indent-10 md:mt-5 grow text-lg font-medium text-base text-justify\",\"children\":\"The following specifies the matrix multiply and accumulate instruction to use\"}],[\"$\",\"div\",null,{\"className\":\"indent-10 md:mt-5 grow text-lg font-medium text-base text-justify\",\"children\":\"$L12\"}],[\"$\",\"div\",null,{\"className\":\"indent-10 md:mt-5 grow text-lg font-medium text-base text-justify\",\"children\":[\"To specify shared memory layout for the matrix \",[\"$\",\"$L5\",null,{\"latex\":\"A\",\"className\":\"mt-10\"}],\". This layout has at least \",[\"$\",\"$L5\",null,{\"latex\":\"3\",\"className\":\"mt-10\"}],\" modes, where the first mode is the shape of the block matrix for a single MMA instruction. The next two modes describe how many times the MMA is repeated traversing the row and columns of \",[\"$\",\"$L5\",null,{\"latex\":\"A\",\"className\":\"mt-10\"}],\". This layout is \",[\"$\",\"span\",null,{\"className\":\"font-semibold\",\"children\":\"swizzled\"}],\" to avoid smem bank conflict.\"]}],[\"$\",\"div\",null,{\"className\":\"indent-10 md:mt-5 grow text-lg font-medium text-base text-justify\",\"children\":\"$L13\"}],[\"$\",\"div\",null,{\"className\":\"indent-10 md:mt-5 grow text-lg font-medium text-base text-justify\",\"children\":[\"Tensor memory accelerator to load \",[\"$\",\"$L5\",null,{\"latex\":\"A\",\"className\":\"mt-10\"}],\" from global to shared memory state space is configured as follows \",\"$L14\"]}],[\"$\",\"div\",null,{\"className\":\"indent-10 md:mt-5 grow text-lg font-medium text-base text-justify\",\"children\":\"Then the kernel is lanuched, specifying the thread block and grid dimensions as appropriate.\"}]]}]]}]\n"])</script><script>self.__next_f.push([1,"a:[\"$\",\"div\",\"2\",{\"children\":[[\"$\",\"div\",null,{\"className\":\" pt-20 font-bold text-2xl\",\"id\":\"section-2\",\"children\":\"GEMM Stages\"}],[\"$\",\"div\",null,{\"className\":\"indent-10 md:mt-10 grow text-lg font-medium text-base text-justify\",\"children\":[[\"$\",\"div\",null,{\"className\":\"indent-10 md:mt-5 grow text-lg font-medium text-base text-justify\",\"children\":\"Before delving into device code let us give a conceptual overview of what happens during the GEMM computation.\"}],[\"$\",\"div\",null,{\"className\":\"indent-10 md:mt-5 grow text-lg font-medium text-base text-justify\",\"children\":[\"The \",[\"$\",\"span\",null,{\"className\":\"font-semibold\",\"children\":\"prologue\"}],\" is what happens before the matrix multiply instruction occurs. The most important function is to load the data via TMA. This is done by performing the necessary indexing: block, thread, warp ID, which is useful for locating which block matrix the MMA will calculate, which data it should load, the TMA and MMA tensor view. The relevant shared and tensor memory needs to be allocated. Setting up pipelines PipelineTmaUmma for consumer-producer between data loading and MMA, PipelineUmmaAsync for signally accumulation completion.\"]}],[\"$\",\"div\",null,{\"className\":\"indent-10 md:mt-5 grow text-lg font-medium text-base text-justify\",\"children\":[\"The \",[\"$\",\"span\",null,{\"className\":\"font-semibold\",\"children\":\"mainloop\"}],\" iteratively fetches data, computes MMA and accumulates across the reduction dimension.\"]}],[\"$\",\"div\",null,{\"className\":\"indent-10 md:mt-5 grow text-lg font-medium text-base text-justify\",\"children\":[\"The \",[\"$\",\"span\",null,{\"className\":\"font-semibold\",\"children\":\"epilogue\"}],\" loads data from tensor memory to register, fuse operation on \",[\"$\",\"$L5\",null,{\"latex\":\"C\",\"className\":\"mt-10\"}],\" matrix and performs necessary data conversion. This stages deallocates tensor memory and stores results back to global memory.\"]}]]}]]}]\n"])</script><script>self.__next_f.push([1,"b:[\"$\",\"$L15\",null,{}]\nc:[\"$\",\"script\",\"script-0\",{\"src\":\"/_next/static/chunks/e02326bdb730da03.js\",\"async\":true,\"nonce\":\"$undefined\"}]\nd:[\"$\",\"script\",\"script-1\",{\"src\":\"/_next/static/chunks/bc166ea53d390db7.js\",\"async\":true,\"nonce\":\"$undefined\"}]\ne:[\"$\",\"script\",\"script-2\",{\"src\":\"/_next/static/chunks/5ad9eb95768fc0a4.js\",\"async\":true,\"nonce\":\"$undefined\"}]\nf:[\"$\",\"$L16\",null,{\"children\":[\"$\",\"$17\",null,{\"name\":\"Next.MetadataOutlet\",\"children\":\"$@18\"}]}]\n10:[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$L19\",null,{\"children\":\"$L1a\"}],[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$L1b\",null,{\"children\":[\"$\",\"$17\",null,{\"name\":\"Next.Metadata\",\"children\":\"$L1c\"}]}]}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}]\n"])</script><script>self.__next_f.push([1,"1a:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n"])</script><script>self.__next_f.push([1,"1d:I[87718,[\"/_next/static/chunks/988ea292de4c4c73.js\",\"/_next/static/chunks/7a959126392b4956.js\"],\"IconMark\"]\n18:null\n1c:[[\"$\",\"title\",\"0\",{\"children\":\"Claire Zhao Blog\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Claire Zhao's Blog on AI and Math\"}],[\"$\",\"link\",\"2\",{\"rel\":\"icon\",\"href\":\"/favicon.ico?favicon.e10ff5c7.ico\",\"sizes\":\"1176x1032\",\"type\":\"image/x-icon\"}],[\"$\",\"$L1d\",\"3\",{}]]\n"])</script><script>self.__next_f.push([1,"1e:I[66832,[\"/_next/static/chunks/e02326bdb730da03.js\",\"/_next/static/chunks/bc166ea53d390db7.js\",\"/_next/static/chunks/5ad9eb95768fc0a4.js\"],\"default\"]\n"])</script><script>self.__next_f.push([1,"12:[\"$\",\"$L1e\",null,{\"code\":\"op = tcgen05.MmaF16BF16Op(\\n    io_dtype,\\n    acc_dtype,\\n    mma_inst_shape_mnk,\\n    tcgen05.CtaGroup.ONE,   # issue granularity\\n    tcgen05.OperandSource.SMEM,\\n    tcgen05.OperandMajorMode.K, # matrix A reduction dimension\\n    tcgen05.OperandMajorMode.K, # matrix B reduction dimension\\n)\\ntiled_mma = cute.make_tiled_mma(op)\\n\",\"tokens\":[[{\"content\":\"op = tcgen05.\",\"offset\":0,\"color\":\"#EEF0F9\",\"fontStyle\":0},{\"content\":\"MmaF16BF16Op\",\"offset\":13,\"color\":\"#00DAEF\",\"fontStyle\":0},{\"content\":\"(\",\"offset\":25,\"color\":\"#EEF0F9\",\"fontStyle\":0}],[{\"content\":\"    io_dtype,\",\"offset\":27,\"color\":\"#EEF0F9\",\"fontStyle\":0}],[{\"content\":\"    acc_dtype,\",\"offset\":41,\"color\":\"#EEF0F9\",\"fontStyle\":0}],[{\"content\":\"    mma_inst_shape_mnk,\",\"offset\":56,\"color\":\"#EEF0F9\",\"fontStyle\":0}],[{\"content\":\"    tcgen05.CtaGroup.\",\"offset\":80,\"color\":\"#EEF0F9\",\"fontStyle\":0},{\"content\":\"ONE\",\"offset\":101,\"color\":\"#FFD493\",\"fontStyle\":0},{\"content\":\",   \",\"offset\":104,\"color\":\"#EEF0F9\",\"fontStyle\":0},{\"content\":\"# issue granularity\",\"offset\":108,\"color\":\"#EEF0F98F\",\"fontStyle\":1}],[{\"content\":\"    tcgen05.OperandSource.\",\"offset\":128,\"color\":\"#EEF0F9\",\"fontStyle\":0},{\"content\":\"SMEM\",\"offset\":154,\"color\":\"#FFD493\",\"fontStyle\":0},{\"content\":\",\",\"offset\":158,\"color\":\"#EEF0F9\",\"fontStyle\":0}],[{\"content\":\"    tcgen05.OperandMajorMode.K, \",\"offset\":160,\"color\":\"#EEF0F9\",\"fontStyle\":0},{\"content\":\"# matrix A reduction dimension\",\"offset\":192,\"color\":\"#EEF0F98F\",\"fontStyle\":1}],[{\"content\":\"    tcgen05.OperandMajorMode.K, \",\"offset\":223,\"color\":\"#EEF0F9\",\"fontStyle\":0},{\"content\":\"# matrix B reduction dimension\",\"offset\":255,\"color\":\"#EEF0F98F\",\"fontStyle\":1}],[{\"content\":\")\",\"offset\":286,\"color\":\"#EEF0F9\",\"fontStyle\":0}],[{\"content\":\"tiled_mma = cute.\",\"offset\":288,\"color\":\"#EEF0F9\",\"fontStyle\":0},{\"content\":\"make_tiled_mma\",\"offset\":305,\"color\":\"#00DAEF\",\"fontStyle\":0},{\"content\":\"(op)\",\"offset\":319,\"color\":\"#EEF0F9\",\"fontStyle\":0}],[]]}]\n"])</script><script>self.__next_f.push([1,"13:[\"$\",\"$L1e\",null,{\"code\":\"a_smem_layout = cutlass.utils.blackwell_helpers.make_smem_layout_a(\\n    tiled_mma,\\n    mma_tiler_mnk,\\n    a.element_type,\\n    ab_stages,\\n)\\na_smem_layout_one_stage = cute.select(a_smem_layout, mode=[0, 1, 2])\\n\",\"tokens\":[[{\"content\":\"a_smem_layout = cutlass.utils.blackwell_helpers.\",\"offset\":0,\"color\":\"#EEF0F9\",\"fontStyle\":0},{\"content\":\"make_smem_layout_a\",\"offset\":48,\"color\":\"#00DAEF\",\"fontStyle\":0},{\"content\":\"(\",\"offset\":66,\"color\":\"#EEF0F9\",\"fontStyle\":0}],[{\"content\":\"    tiled_mma,\",\"offset\":68,\"color\":\"#EEF0F9\",\"fontStyle\":0}],[{\"content\":\"    mma_tiler_mnk,\",\"offset\":83,\"color\":\"#EEF0F9\",\"fontStyle\":0}],[{\"content\":\"    a.element_type,\",\"offset\":102,\"color\":\"#EEF0F9\",\"fontStyle\":0}],[{\"content\":\"    ab_stages,\",\"offset\":122,\"color\":\"#EEF0F9\",\"fontStyle\":0}],[{\"content\":\")\",\"offset\":137,\"color\":\"#EEF0F9\",\"fontStyle\":0}],[{\"content\":\"a_smem_layout_one_stage = cute.\",\"offset\":139,\"color\":\"#EEF0F9\",\"fontStyle\":0},{\"content\":\"select\",\"offset\":170,\"color\":\"#00DAEF\",\"fontStyle\":0},{\"content\":\"(a_smem_layout, \",\"offset\":176,\"color\":\"#EEF0F9\",\"fontStyle\":0},{\"content\":\"mode\",\"offset\":192,\"color\":\"#4BF3C8\",\"fontStyle\":1},{\"content\":\"=[\",\"offset\":196,\"color\":\"#EEF0F9\",\"fontStyle\":0},{\"content\":\"0\",\"offset\":198,\"color\":\"#FFD493\",\"fontStyle\":0},{\"content\":\", \",\"offset\":199,\"color\":\"#EEF0F9\",\"fontStyle\":0},{\"content\":\"1\",\"offset\":201,\"color\":\"#FFD493\",\"fontStyle\":0},{\"content\":\", \",\"offset\":202,\"color\":\"#EEF0F9\",\"fontStyle\":0},{\"content\":\"2\",\"offset\":204,\"color\":\"#FFD493\",\"fontStyle\":0},{\"content\":\"])\",\"offset\":205,\"color\":\"#EEF0F9\",\"fontStyle\":0}],[]]}]\n"])</script><script>self.__next_f.push([1,"14:[\"$\",\"$L1e\",null,{\"code\":\"op = cute.nvgpu.cpasync.CopyBulkTensorTileG2SOp(tcgen05.CtaGroup.ONE)\\na_tma_atom, a_tma_tensor = cute.nvgpu.make_tiled_tma_atom_A(\\n    op,\\n    a,  # the matrix A\\n    a_smem_layout_one_stage,\\n    mma_tiler_mnk,\\n    tiled_mma,\\n)\\n\",\"tokens\":[[{\"content\":\"op = cute.nvgpu.cpasync.\",\"offset\":0,\"color\":\"#EEF0F9\",\"fontStyle\":0},{\"content\":\"CopyBulkTensorTileG2SOp\",\"offset\":24,\"color\":\"#00DAEF\",\"fontStyle\":0},{\"content\":\"(tcgen05.CtaGroup.\",\"offset\":47,\"color\":\"#EEF0F9\",\"fontStyle\":0},{\"content\":\"ONE\",\"offset\":65,\"color\":\"#FFD493\",\"fontStyle\":0},{\"content\":\")\",\"offset\":68,\"color\":\"#EEF0F9\",\"fontStyle\":0}],[{\"content\":\"a_tma_atom, a_tma_tensor = cute.nvgpu.\",\"offset\":70,\"color\":\"#EEF0F9\",\"fontStyle\":0},{\"content\":\"make_tiled_tma_atom_A\",\"offset\":108,\"color\":\"#00DAEF\",\"fontStyle\":0},{\"content\":\"(\",\"offset\":129,\"color\":\"#EEF0F9\",\"fontStyle\":0}],[{\"content\":\"    op,\",\"offset\":131,\"color\":\"#EEF0F9\",\"fontStyle\":0}],[{\"content\":\"    a,  \",\"offset\":139,\"color\":\"#EEF0F9\",\"fontStyle\":0},{\"content\":\"# the matrix A\",\"offset\":147,\"color\":\"#EEF0F98F\",\"fontStyle\":1}],[{\"content\":\"    a_smem_layout_one_stage,\",\"offset\":162,\"color\":\"#EEF0F9\",\"fontStyle\":0}],[{\"content\":\"    mma_tiler_mnk,\",\"offset\":191,\"color\":\"#EEF0F9\",\"fontStyle\":0}],[{\"content\":\"    tiled_mma,\",\"offset\":210,\"color\":\"#EEF0F9\",\"fontStyle\":0}],[{\"content\":\")\",\"offset\":225,\"color\":\"#EEF0F9\",\"fontStyle\":0}],[]]}]\n"])</script></body></html>