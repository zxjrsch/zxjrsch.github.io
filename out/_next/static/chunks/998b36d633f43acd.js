(globalThis.TURBOPACK||(globalThis.TURBOPACK=[])).push(["object"==typeof document?document.currentScript:void 0,646,(e,t,a)=>{"use strict";Object.defineProperty(a,"__esModule",{value:!0}),Object.defineProperty(a,"warnOnce",{enumerable:!0,get:function(){return s}});let s=e=>{}},90320,e=>{"use strict";var t=e.i(45360),a=e.i(87715),s=e.i(1565),l=e.i(56691);function i(e){let s,l,i,m=(0,a.c)(7),{sectionTitle:n,sectionContent:d}=e;return m[0]!==n?(s=n&&(0,t.jsx)("div",{className:" pt-20 font-bold text-2xl",id:"section-2",children:n}),m[0]=n,m[1]=s):s=m[1],m[2]!==d?(l=(0,t.jsx)("div",{className:"indent-10 md:mt-10 grow text-lg font-medium text-base text-justify",children:d}),m[2]=d,m[3]=l):l=m[3],m[4]!==s||m[5]!==l?(i=(0,t.jsxs)("div",{children:[s,l]}),m[4]=s,m[5]=l,m[6]=i):i=m[6],i}function m(e){let i,m,d,r,o,x,c,f,u=(0,a.c)(16),{title:h,date:j,body:N}=e;return u[0]===Symbol.for("react.memo_cache_sentinel")?(i=(0,t.jsx)("div",{className:"flex flex-row justify-center pt-15",children:(0,t.jsx)(s.default,{})}),u[0]=i):i=u[0],u[1]!==h?(m=(0,t.jsx)("div",{className:"text-3xl font-bold flex justify-center",children:h}),u[1]=h,u[2]=m):m=u[2],u[3]!==j?(d=(0,t.jsx)("div",{className:"text-sm flex justify-center pt-5",children:j}),u[3]=j,u[4]=d):d=u[4],u[5]!==N?(r=N.map(n),u[5]=N,u[6]=r):r=u[6],u[7]!==r?(o=(0,t.jsx)("div",{className:"",children:r}),u[7]=r,u[8]=o):o=u[8],u[9]!==m||u[10]!==d||u[11]!==o?(x=(0,t.jsx)("div",{className:"grow flex justify-center w-full pt-10 md:pt-15 px-3",children:(0,t.jsxs)("div",{className:"flex flex-col lg:min-w-1/2 lg:max-w-1/2",children:[m,d,o]})}),u[9]=m,u[10]=d,u[11]=o,u[12]=x):x=u[12],u[13]===Symbol.for("react.memo_cache_sentinel")?(c=(0,t.jsx)(l.default,{}),u[13]=c):c=u[13],u[14]!==x?(f=(0,t.jsxs)("div",{className:"flex flex-col justify-center min-h-screen",children:[i,x,c]}),u[14]=x,u[15]=f):f=u[15],f}function n(e,a){return(0,t.jsx)(i,{sectionTitle:e.title,sectionContent:e.paragraph},a)}e.s(["default",()=>m])},13068,e=>{"use strict";var t=e.i(45360),a=e.i(87715),s=e.i(90320),l=e.i(96045);let i={title:(0,t.jsx)(t.Fragment,{children:"Pre-Training LLM with NVFP4"}),date:"Jan 30",tags:null,content:[{paragraph:(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)("div",{className:"indent-10 md:mt-5 grow text-lg font-medium text-base text-justify",children:["Consider how a real number ",(0,t.jsx)(l.default,{latex:"x",className:"mt-10"})," can be represented on a computer. If ",(0,t.jsx)(l.default,{latex:"x \\neq 0",className:"mt-10"})," then ",(0,t.jsx)(l.default,{latex:"x=\\frac{x}{|x|}\\times |x|=(-1)^S\\times |x|",displayMode:!0,className:"mt-10"})," where ",(0,t.jsx)(l.default,{latex:"(-1)^S = x/|x|",className:"mt-10"})," is the sign of ",(0,t.jsx)(l.default,{latex:"x",className:"mt-10"})," and can be represented with one bit ",(0,t.jsx)(l.default,{latex:"S\\in\\{0, 1\\}",className:"mt-10"}),". For the positive number ",(0,t.jsx)(l.default,{latex:"a=|x|",className:"mt-10"})," there exists a smallest ",(0,t.jsx)(l.default,{latex:"E\\in\\mathbb{Z}",className:"mt-10"})," such that ",(0,t.jsx)(l.default,{latex:"x\\in[0,\\, 2^{E+1}]",className:"mt-10"}),". Now we can divide this interval into two equal halves. By definition of ",(0,t.jsx)(l.default,{latex:"E",className:"mt-10"})," we know that ",(0,t.jsx)(l.default,{latex:"a\\in [2^{E}, 2^{E+1}]",className:"mt-10"}),". We can again divide the interval ",(0,t.jsx)(l.default,{latex:"[2^{E}, 2^{E+1}]",className:"mt-10"})," into two equal halves and ",(0,t.jsx)(l.default,{latex:"x",className:"mt-10"})," lies in either the left half or the right half (to breaE the tie, if ",(0,t.jsx)(l.default,{latex:"a",className:"mt-10"})," likes in the middle, then we say it lies on the right half). As we make the sequence of interval partitions, the positive real number ",(0,t.jsx)(l.default,{latex:"a",className:"mt-10"})," lies in either the left or the right half. Associate left with ",(0,t.jsx)(l.default,{latex:"0",className:"mt-10"})," right with ",(0,t.jsx)(l.default,{latex:"1",className:"mt-10"})," we obtain a binary sequence ",(0,t.jsx)(l.default,{latex:"\\{a_j\\}_{j \\geq 1}",className:"mt-10"}),". It is clear that for the ",(0,t.jsx)(l.default,{latex:"n",className:"mt-10"}),"-th partition the situation is ",(0,t.jsx)(l.default,{latex:"a = 2^{E} + a_1\\times\\frac{2^{E}}{2}+\\dots+a_n\\times\\frac{2^{E}}{2^n}+\\varepsilon_n",displayMode:!0,className:"mt-10"})," where ",(0,t.jsx)(l.default,{latex:"0\\leq \\varepsilon_n < 2^{E-n}",className:"mt-10"})," is less than the length of the half interval in the ",(0,t.jsx)(l.default,{latex:"n",className:"mt-10"}),"-th partition. So the positive real number ",(0,t.jsx)(l.default,{latex:"a",className:"mt-10"}),", and a desired precision ",(0,t.jsx)(l.default,{latex:"\\varepsilon>0",className:"mt-10"}),", we can choose an integer ",(0,t.jsx)(l.default,{latex:"m > 0",className:"mt-10"})," such that ",(0,t.jsx)(l.default,{latex:"2^{E-m}<\\varepsilon",className:"mt-10"})," so that the number ",(0,t.jsx)(l.default,{latex:"b_m = 2^{E} + a_1\\times\\frac{2^{E}}{2}+\\dots+a_m\\times\\frac{2^{E}}{2^m}",displayMode:!0,className:"mt-10"})," which is representable by a binary sequence of length ",(0,t.jsx)(l.default,{latex:"m",className:"mt-10"}),", approximates ",(0,t.jsx)(l.default,{latex:"a",className:"mt-10"})," to within ",(0,t.jsx)(l.default,{latex:"\\varepsilon",className:"mt-10"}),", namely ",(0,t.jsx)(l.default,{latex:"0\\leq a -b_m < 2^{E-m}< \\varepsilon",displayMode:!0,className:"mt-10"})," Since ",(0,t.jsx)(l.default,{latex:"x=(-1)^S\\times b_m + \\varepsilon_m",className:"mt-10"})," we can write ",(0,t.jsx)(l.default,{latex:"x=(-1)^S\\times \\left(1+ \\frac{a_1}{2}+\\dots+\\frac{a_m}{2^m}\\right) \\times 2^E + \\varepsilon_m",displayMode:!0,className:"mt-10"})," Hardware approximates ",(0,t.jsx)(l.default,{latex:"x",className:"mt-10"})," by storing one bit ",(0,t.jsx)(l.default,{latex:"S",className:"mt-10"})," for the ",(0,t.jsx)("span",{className:"font-semibold",children:"sign"})," of ",(0,t.jsx)(l.default,{latex:"x",className:"mt-10"}),", another ",(0,t.jsx)(l.default,{latex:"m",className:"mt-10"})," bits ",(0,t.jsx)(l.default,{latex:"a_1\\dots a_m",className:"mt-10"})," called the mantissa of ",(0,t.jsx)(l.default,{latex:"x",className:"mt-10"}),", the bit length of which determines an upper bounds on the error ",(0,t.jsx)(l.default,{latex:"\\varepsilon_m",className:"mt-10"})," of approximating ",(0,t.jsx)(l.default,{latex:"|x|",className:"mt-10"})," by ",(0,t.jsx)(l.default,{latex:"b_m",className:"mt-10"}),", together with a representation of the ",(0,t.jsx)("span",{className:"font-semibold",children:"exponent"})," ",(0,t.jsx)(l.default,{latex:"E\\in\\mathbb{Z}",className:"mt-10"}),"."]}),(0,t.jsxs)("div",{className:"indent-10 md:mt-5 grow text-lg font-medium text-base text-justify",children:["Now we need a scheme for representing the integer ",(0,t.jsx)(l.default,{latex:"E",className:"mt-10"})," in bits. Suppose that ",(0,t.jsx)(l.default,{latex:"k",className:"mt-10"})," bits are designated to store the exponent, then there are ",(0,t.jsx)(l.default,{latex:"2^k",className:"mt-10"})," configurations, meaning that the real number the float can approximate spans ",(0,t.jsx)(l.default,{latex:"k",className:"mt-10"})," orders of magnitudes. Naturally we want to choose ",(0,t.jsx)(l.default,{latex:"k",className:"mt-10"})," orders of magnitudes about the multiplicative unit ",(0,t.jsx)(l.default,{latex:"2^0=1",className:"mt-10"}),". Customarily we designate ",(0,t.jsx)(l.default,{latex:"2^{k-1}",className:"mt-10"})," of the ",(0,t.jsx)(l.default,{latex:"2^k",className:"mt-10"})," orders of magnitudes to be at or below the unit, and another ",(0,t.jsx)(l.default,{latex:"2^{k-1}",className:"mt-10"})," orders of magnitudes to be above the unit. The hardware implementation is to store the integer exponent ",(0,t.jsx)(l.default,{latex:"E",className:"mt-10"})," with an non-negative integer ",(0,t.jsx)(l.default,{latex:"E'",className:"mt-10"})," such that ",(0,t.jsx)(l.default,{latex:"E' = E + 2^{k-1}-1",displayMode:!0,className:"mt-10"})," this way the smallest order of magnitude (with respect this dtype) ",(0,t.jsx)(l.default,{latex:"E=1-2^{k-1}",className:"mt-10"})," is stored as ",(0,t.jsx)(l.default,{latex:"E'=0",className:"mt-10"})," whereas the largest order of magnitude ",(0,t.jsx)(l.default,{latex:"E=2^{k-1}",className:"mt-10"})," is stored as ",(0,t.jsx)(l.default,{latex:"E'=2^k",className:"mt-10"}),". This scheme is nothing but a bijection from ",(0,t.jsx)(l.default,{latex:"\\{-(2^{k-1}-1),\\dots, -1, 0, 1, \\dots, 2^{k-1}\\}\\longrightarrow \\{0, 1, \\dots, 2^k-1\\}",displayMode:!0,className:"mt-10"})]}),(0,t.jsxs)("div",{className:"indent-10 md:mt-5 grow text-lg font-medium text-base text-justify",children:["The quantity ",(0,t.jsx)(l.default,{latex:"2^{k-1}-1",className:"mt-10"})," is sometimes given the nondescript name ",(0,t.jsx)("span",{className:"font-semibold",children:"bias"})," just to be confusing!"]}),(0,t.jsxs)("div",{className:"indent-10 md:mt-5 grow text-lg font-medium text-base text-justify",children:["The mantissa ",(0,t.jsx)(l.default,{latex:"m",className:"mt-10"}),", which we have until now defined as the bit string ",(0,t.jsx)(l.default,{latex:"a_1\\dots a_m",className:"mt-10"})," should really be identified with the real number that it represents ",(0,t.jsx)(l.default,{latex:"M=\\frac{a_1}{2}+\\dots+\\frac{a_m}{2^m}",displayMode:!0,className:"mt-10"})," and together with ",(0,t.jsx)(l.default,{latex:"E' = E + 2^{k-1}-1",className:"mt-10"})," and the sign ",(0,t.jsx)(l.default,{latex:"S",className:"mt-10"})," represents the real number (approximately) on hardware as ",(0,t.jsx)(l.default,{latex:"(-1)^S\\times (1+M)\\times 2^{E' - \\text{bias}}",displayMode:!0,className:"mt-10"})]}),(0,t.jsxs)("div",{className:"indent-10 md:mt-5 grow text-lg font-medium text-base text-justify",children:["We shall now identify the unsigned integer ",(0,t.jsx)(l.default,{latex:"E'",className:"mt-10"})," with the integer ",(0,t.jsx)(l.default,{latex:"E",className:"mt-10"})," that it is meant to represent."]})]})},{title:(0,t.jsx)(t.Fragment,{children:"Definition"}),paragraph:(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)("div",{className:"indent-10 md:mt-5 grow text-lg font-medium text-base text-justify",children:["Hardware represents floating point numbers in the form ",(0,t.jsx)(l.default,{latex:"(-1)^S\\times(1+M)\\times 2^{E-\\text{bias}}",displayMode:!0,className:"mt-10"})," where ",(0,t.jsx)(l.default,{latex:"S",className:"mt-10"})," determines the sign of the number and is stored with one bit. Depending on the datatype, a choice of ",(0,t.jsx)(l.default,{latex:"m",className:"mt-10"})," bits are devoted to the mantissa ",(0,t.jsx)(l.default,{latex:"M",className:"mt-10"}),", and ",(0,t.jsx)(l.default,{latex:"e",className:"mt-10"})," bits are devoted to the exponent ",(0,t.jsx)(l.default,{latex:"E",className:"mt-10"}),". The datatype thus determined requires ",(0,t.jsx)(l.default,{latex:"1+m+e",className:"mt-10"})," bits to represent a float, and is denoted EeMm. For instance, FP32 is E8M23, FP16 is E5M10 where as BF16 is E8M7."]}),(0,t.jsxs)("div",{className:"indent-10 md:mt-5 grow text-lg font-medium text-base text-justify",children:["Quantization is the operation that maps numbers repreented in a given datatype to numbers in another datatype requiring less number ",(0,t.jsx)(l.default,{latex:"1+m+e",className:"mt-10"})," of bits. Thus quantization is a compression mechanism that reduces storage and communication footprint, and increase compute throughput. The efficiency gained via compression is to be trade-off with degradation in accuracy in one form or antoher."]}),(0,t.jsxs)("div",{className:"indent-10 md:mt-5 grow text-lg font-medium text-base text-justify",children:["In practice one quantizes a set ",(0,t.jsx)(l.default,{latex:"A",className:"mt-10"})," of ",(0,t.jsx)(l.default,{latex:"n",className:"mt-10"})," numbers together. For example, to quantize real numbers ",(0,t.jsx)(l.default,{latex:"a\\in A",className:"mt-10"})," into ",(0,t.jsx)(l.default,{latex:"m",className:"mt-10"})," bit integers ",(0,t.jsx)(l.default,{latex:"-2^{m-1}\\leq q(a)\\leq 2^{m-1}-1",className:"mt-10"}),", we can choose the mapping ",(0,t.jsx)(l.default,{latex:"q(a)= \\text{NearestInteger}\\left(\\frac{2^{m-1}-1}{\\max_{i,j} |A_{ij}|}\\times a\\right)",displayMode:!0,className:"mt-10"})," In particular the scale factor ",(0,t.jsx)(l.default,{latex:"s=({2^{m-1}-1})/{\\max_{i,j} |A_{ij}|}",className:"mt-10"})," is chosen so that the maximum element of ",(0,t.jsx)(l.default,{latex:"A",className:"mt-10"})," gets mapped to ",(0,t.jsx)(l.default,{latex:"2^{m-1}-1",className:"mt-10"}),". Since the mapping ",(0,t.jsx)(l.default,{latex:"q",className:"mt-10"})," is many-to-one we can only hope to dequantize approximately, with error. More precisely, given an integer ",(0,t.jsx)(l.default,{latex:"k=q(a)",className:"mt-10"})," we can map it to ",(0,t.jsx)(l.default,{latex:"Q(k) = \\frac{\\max_{i,j} |A_{ij}|}{2^{m-1}-1}\\times k",displayMode:!0,className:"mt-10"})," and this introduces an error ",(0,t.jsx)(l.default,{latex:"|Q(q(a))-a|",className:"mt-10"}),"."]}),(0,t.jsxs)("div",{className:"indent-10 md:mt-5 grow text-lg font-medium text-base text-justify",children:["In general given a pair of quantization and dequantization maps ",(0,t.jsx)(l.default,{latex:"(q, Q)",className:"mt-10"})," one can measure the ",(0,t.jsx)(l.default,{latex:"L^2",className:"mt-10"})," error  ",(0,t.jsx)(l.default,{latex:"\\mathbb{E}[||Q(q(x))-x||^2]",className:"mt-10"}),"."]})]})},{title:(0,t.jsx)(t.Fragment,{children:"Trainng in NVFP4"}),paragraph:(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)("div",{className:"indent-10 md:mt-5 grow text-lg font-medium text-base text-justify",children:"Based on the papers and documentations I can find, here is a sketch of training LLMs in NVFP4."}),(0,t.jsxs)("div",{className:"indent-10 md:mt-5 grow text-lg font-medium text-base text-justify",children:["Like FP4 and MXFP4, NVFP4 has the bit strcuture of E2M1. The distinction lies in how NVFP4 represent a set ",(0,t.jsx)(l.default,{latex:"T",className:"mt-10"})," of numbers, which we refer to as a tensor. In particular, NVFP4 partitions ",(0,t.jsx)(l.default,{latex:"T",className:"mt-10"})," into subsets of ",(0,t.jsx)(l.default,{latex:"16",className:"mt-10"})," numbers each called a block. Each block is associated with an 8-bit E4M3 number called a block scale factor ",(0,t.jsx)(l.default,{latex:"s",className:"mt-10"})," such that each one of the ",(0,t.jsx)(l.default,{latex:"16",className:"mt-10"})," four bit numbers ",(0,t.jsx)(l.default,{latex:"x_{quantized}",className:"mt-10"})," belonging to the same block is reconstructed with ",(0,t.jsx)(l.default,{latex:"x=s\\times x_{quantized}",className:"mt-10"})," . Additionally, a FP32 number is asspciated with the tensor ",(0,t.jsx)(l.default,{latex:"T",className:"mt-10"})," itself, called the tensor scale factor."]}),(0,t.jsxs)("div",{className:"indent-10 md:mt-5 grow text-lg font-medium text-base text-justify",children:["By contrast each MXFP4 partitions consists of ",(0,t.jsx)(l.default,{latex:"32",className:"mt-10"})," numbers, and its block scale factor is E8M0 (i.e. round to the nearest power of two). It can be shown that the expected square error with E8M0 is larger than that of E4M3, with the tradeoff being E8M0 has less overhead. The said parititon and scaling in NVFP4 is handled by specialized tensor core harware."]}),(0,t.jsxs)("div",{className:"indent-10 md:mt-5 grow text-lg font-medium text-base text-justify",children:["Given that E2M1 and E4M3 can represent numbers with maximum absolute value of ",(0,t.jsx)(l.default,{latex:"6",className:"mt-10"})," and ",(0,t.jsx)(l.default,{latex:"448",className:"mt-10"})," respectively, the tensor scale factor for a tensor ",(0,t.jsx)(l.default,{latex:"T_I",className:"mt-10"})," indexed by a set ",(0,t.jsx)(l.default,{latex:"I",className:"mt-10"})," is ",(0,t.jsx)(l.default,{latex:"s_{tensor} = \\frac{6\\times 448}{\\max_{i\\in I}|T_i|}",displayMode:!0,className:"mt-10"})," the tensor dequantization scale is ",(0,t.jsx)(l.default,{latex:"1/s_{tensor}",className:"mt-10"})," and is stored in FP32. Let ",(0,t.jsx)(l.default,{latex:"J\\subset I",className:"mt-10"})," be an indexing set for a block in ",(0,t.jsx)(l.default,{latex:"T",className:"mt-10"}),", the corresponding block scale factor that is ",(0,t.jsx)(l.default,{latex:"s_{block\\, J}=\\frac{6}{\\max_{j\\in J}|T_j|}",displayMode:!0,className:"mt-10"})," In fact, the block dequantization scale factor ",(0,t.jsx)(l.default,{latex:"\\delta_{\\text{block, J}}",className:"mt-10"})," is stored in FP8 on the tensor core as ",(0,t.jsx)(l.default,{latex:"\\delta_{\\text{block, J}} = e4m3\\left(\\frac{s_{tensor}}{s_{block\\, J}}\\right)",displayMode:!0,className:"mt-10"})]}),(0,t.jsxs)("div",{className:"indent-10 md:mt-5 grow text-lg font-medium text-base text-justify",children:["Each block ",(0,t.jsx)(l.default,{latex:"T_J",className:"mt-10"})," gets quantized as ",(0,t.jsx)(l.default,{latex:"\\widehat{T}_J = \\text{fp4}(s_{block\\, J}\\cdot T_J)",displayMode:!0,className:"mt-10"})," and partial dot during GEMM product is computed as ",(0,t.jsx)(l.default,{latex:"\\lambda_{JK} (\\widehat{T_J} \\cdot \\widehat{T_K}) ",displayMode:!0,className:"mt-10"})," where ",(0,t.jsx)(l.default,{latex:"\\lambda_{JK}=\\delta_{\\text{block, J}} \\times \\delta_{\\text{block, K}}",displayMode:!0,className:"mt-10"})," After GEMM the tensor dequantization scales are applied."]}),(0,t.jsx)("div",{className:"indent-10 md:mt-5 grow text-lg font-medium text-base text-justify",children:"There are experiments showing NVFP4 should be used in earlier layers of the forward pass direction of a transformer, while keeping later layers in higher precision."})]})},{title:(0,t.jsx)(t.Fragment,{children:"Random Hadamard Transform"}),paragraph:(0,t.jsx)(t.Fragment,{children:(0,t.jsxs)("div",{className:"indent-10 md:mt-5 grow text-lg font-medium text-base text-justify",children:["Hadamard matrices of dimension ",(0,t.jsx)(l.default,{latex:"d=2^{k}",className:"mt-10"})," for an integer ",(0,t.jsx)(l.default,{latex:"k",className:"mt-10"})," satisfies ",(0,t.jsx)(l.default,{latex:"H_d={1}/{\\sqrt{2}}H_2\\otimes H_{d/2}",displayMode:!0,className:"mt-10"})," and ",(0,t.jsx)(l.default,{latex:"HH^\\top=I",className:"mt-10"}),". We shall consider a randomized Hadamard matrix ",(0,t.jsx)(l.default,{latex:"S_dH_d",className:"mt-10"})," where ",(0,t.jsx)(l.default,{latex:"S_d",className:"mt-10"})," is a diagonal matrix of values ",(0,t.jsx)(l.default,{latex:"\\pm 1",className:"mt-10"})," chosen uniformly at random. In training, instead of operating on tensors ",(0,t.jsx)(l.default,{latex:"T_I",className:"mt-10"})," one qpplies the above NVFP4 on the random Hadamard transformed tiles ",(0,t.jsx)(l.default,{latex:"(S_dH_d)T_J",displayMode:!0,className:"mt-10"})," of the tensor. In some experiments ",(0,t.jsx)(l.default,{latex:"d=16",className:"mt-10"})," is applied to inputs of weight gradient GEMM."]})})}]};function m(){let e,l=(0,a.c)(1);return l[0]===Symbol.for("react.memo_cache_sentinel")?(e=(0,t.jsx)(s.default,{title:i.title,date:i.date,body:i.content}),l[0]=e):e=l[0],e}e.s(["default",()=>m],13068)}]);